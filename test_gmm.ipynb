{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "284a86e5-93b7-45e9-8ff9-515aff39d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import numpy.random as rng\n",
    "import torch as th\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as D\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d5cae7-2bcf-4cde-be39-b92eabb3d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mixture_gaussians(mixture_coeff, mu, sigma, n_samples, hard=False):\n",
    "    rv = th.randn((n_samples, mu.shape[0])) * sigma + mu \n",
    "    components = th.nn.functional.gumbel_softmax(th.tile(mixture_coeff, (n_samples,1)), tau=0.5, hard=hard)\n",
    "    samples = (rv * components).sum(1)\n",
    "    return samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "22665880-ba2c-44c2-aaae-3ae394724bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 50])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu = th.tensor([-1, 1]).float()\n",
    "sigma = th.tensor([0.1, 0.1]).float()\n",
    "mixture_coeff_logits = th.tensor([1, 0]).float()\n",
    "\n",
    "n_students = 100\n",
    "n_trials = 50\n",
    "\n",
    "with th.no_grad():\n",
    "    abilities = sample_mixture_gaussians(mixture_coeff_logits, mu, sigma, n_students, hard=True)\n",
    "    probs = th.sigmoid(abilities)\n",
    "    trial_probs = th.tile(probs, (n_trials, 1)).T\n",
    "    y = th.bernoulli(trial_probs).float()\n",
    "\n",
    "plt.hist(abilities.numpy(), bins=50)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e289ad3d-0faa-48ab-a819-4f53c62d45eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2325.6907, Valid: 617.7676\n",
      "Train: 2307.9282, Valid: 613.0480\n",
      "Train: 2290.0676, Valid: 608.4716\n",
      "Train: 2274.2588, Valid: 604.6531\n",
      "Train: 2261.6106, Valid: 601.8153\n",
      "Train: 2251.9941, Valid: 599.8135\n",
      "Train: 2244.8396, Valid: 598.4216\n",
      "Train: 2239.5757, Valid: 597.4563\n",
      "Train: 2235.7334, Valid: 596.7876\n",
      "Train: 2232.9470, Valid: 596.3251\n",
      "Train: 2230.9375, Valid: 596.0055\n",
      "Train: 2229.4961, Valid: 595.7847\n",
      "Train: 2228.4658, Valid: 595.6323\n",
      "Train: 2227.7314, Valid: 595.5272\n",
      "Train: 2227.2041, Valid: 595.4546\n",
      "Train: 2226.8159, Valid: 595.4041\n",
      "Train: 2226.5129, Valid: 595.3680\n",
      "Train: 2226.2515, Valid: 595.3403\n",
      "Train: 2225.9912, Valid: 595.3156\n",
      "Train: 2225.6919, Valid: 595.2890\n",
      "Train: 2225.3025, Valid: 595.2545\n",
      "Train: 2224.7478, Valid: 595.2039\n",
      "Train: 2223.8984, Valid: 595.1237\n",
      "Train: 2222.5261, Valid: 594.9902\n",
      "Train: 2220.2524, Valid: 594.7634\n",
      "Train: 2216.6575, Valid: 594.3986\n",
      "Train: 2211.9031, Valid: 593.9102\n",
      "Train: 2207.1140, Valid: 593.3705\n",
      "Train: 2203.1411, Valid: 592.8206\n",
      "Train: 2200.0720, Valid: 592.3163\n",
      "Train: 2197.7380, Valid: 591.8899\n",
      "Train: 2195.9629, Valid: 591.5508\n",
      "Train: 2194.6052, Valid: 591.2924\n",
      "Train: 2193.5579, Valid: 591.0992\n",
      "Train: 2192.7415, Valid: 590.9561\n",
      "Train: 2192.0989, Valid: 590.8506\n",
      "Train: 2191.5884, Valid: 590.7731\n",
      "Train: 2191.1787, Valid: 590.7169\n",
      "Train: 2190.8477, Valid: 590.6768\n",
      "Train: 2190.5776, Valid: 590.6487\n",
      "Train: 2190.3560, Valid: 590.6299\n",
      "Train: 2190.1731, Valid: 590.6182\n",
      "Train: 2190.0210, Valid: 590.6119\n",
      "Train: 2189.8943, Valid: 590.6097\n",
      "Train: 2189.7878, Valid: 590.6105\n",
      "Train: 2189.6980, Valid: 590.6139\n",
      "Train: 2189.6223, Valid: 590.6190\n",
      "Train: 2189.5581, Valid: 590.6255\n",
      "Train: 2189.5039, Valid: 590.6330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  3.,  10.,  23.,  51.,  74., 143., 212., 282., 352., 426., 436.,\n",
       "        370., 350., 249., 185., 117.,  50.,  33.,  15.,   6.,   0.,   1.,\n",
       "          1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   4.,  10.,\n",
       "         25.,  32.,  68., 111., 165., 167., 206., 242., 197., 136., 104.,\n",
       "         75.,  35.,  16.,  10.,   5.,   1.]),\n",
       " array([-1.8372052e+00, -1.7637182e+00, -1.6902313e+00, -1.6167445e+00,\n",
       "        -1.5432576e+00, -1.4697707e+00, -1.3962837e+00, -1.3227968e+00,\n",
       "        -1.2493100e+00, -1.1758231e+00, -1.1023362e+00, -1.0288492e+00,\n",
       "        -9.5536238e-01, -8.8187546e-01, -8.0838859e-01, -7.3490167e-01,\n",
       "        -6.6141474e-01, -5.8792788e-01, -5.1444095e-01, -4.4095406e-01,\n",
       "        -3.6746716e-01, -2.9398027e-01, -2.2049336e-01, -1.4700647e-01,\n",
       "        -7.3519565e-02, -3.2663345e-05,  7.3454238e-02,  1.4694114e-01,\n",
       "         2.2042803e-01,  2.9391494e-01,  3.6740184e-01,  4.4088873e-01,\n",
       "         5.1437563e-01,  5.8786255e-01,  6.6134942e-01,  7.3483634e-01,\n",
       "         8.0832326e-01,  8.8181013e-01,  9.5529705e-01,  1.0287839e+00,\n",
       "         1.1022708e+00,  1.1757578e+00,  1.2492447e+00,  1.3227315e+00,\n",
       "         1.3962184e+00,  1.4697053e+00,  1.5431923e+00,  1.6166792e+00,\n",
       "         1.6901660e+00,  1.7636529e+00,  1.8371398e+00], dtype=float32),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with th.no_grad():\n",
    "    abilities_grid = th.linspace(-3, 3, 30)\n",
    "    \n",
    "repy = th.tile(y[:,:,None], (1,1,abilities_grid.shape[0]))\n",
    "\n",
    "n_components = 2\n",
    "\n",
    "weight_logits = th.nn.Parameter(th.randn(n_components,))\n",
    "component_mu = th.nn.Parameter(th.randn(n_components,))\n",
    "component_log_std = th.nn.Parameter(th.randn(n_components,))\n",
    "\n",
    "params = [weight_logits, component_mu, component_log_std]\n",
    "opt = th.optim.Adam(params, lr = 0.001)\n",
    "\n",
    "best_valid_loss = th.inf \n",
    "patience = 500\n",
    "wait_counter = 0\n",
    "\n",
    "best_params = []\n",
    "\n",
    "train_y = repy[:80,:,:]\n",
    "valid_y = repy[80:,:,:]\n",
    "\n",
    "for e in range(10000):\n",
    "    \n",
    "    mix = D.Categorical(logits=weight_logits)\n",
    "    comp = D.Normal(component_mu, th.exp(component_log_std))\n",
    "    gmm = D.MixtureSameFamily(mix, comp)\n",
    "    \n",
    "    alpha = th.tile(abilities_grid, (train_y.shape[0], train_y.shape[1],1))\n",
    "    prob_one = th.sigmoid(alpha)\n",
    "    logprior = gmm.log_prob(alpha)\n",
    "    loglik = ((train_y * th.log(prob_one) + (1-train_y) * th.log(1-prob_one))).sum(1)\n",
    "    loss = -th.logsumexp(loglik + logprior[:,0,:], dim=1).sum()\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    with th.no_grad():\n",
    "        mix = D.Categorical(logits=weight_logits)\n",
    "        comp = D.Normal(component_mu, th.exp(component_log_std))\n",
    "        gmm = D.MixtureSameFamily(mix, comp)\n",
    "\n",
    "        \n",
    "        alpha = th.tile(abilities_grid, (valid_y.shape[0], valid_y.shape[1],1))\n",
    "        prob_one = th.sigmoid(alpha)\n",
    "        logprior = gmm.log_prob(alpha)\n",
    "        loglik = ((valid_y * th.log(prob_one) + (1-valid_y) * th.log(1-prob_one))).sum(1)\n",
    "        valid_loss = -th.logsumexp(loglik + logprior[:,0,:], dim=1).sum()\n",
    "\n",
    "\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_params = copy.deepcopy(params)\n",
    "            wait_counter = 0\n",
    "        else:\n",
    "            wait_counter += 1\n",
    "        \n",
    "        if wait_counter >= patience:\n",
    "            break\n",
    "        \n",
    "    if e % 100 == 0:\n",
    "        print(\"Train: %8.4f, Valid: %8.4f\" % (loss.item(), valid_loss.item()))\n",
    "    \n",
    "    \n",
    "with th.no_grad():\n",
    "    weight_logits, component_mu, component_log_std = best_params\n",
    "    mix = D.Categorical(logits=weight_logits)\n",
    "    comp = D.Normal(component_mu, th.exp(component_log_std))\n",
    "    gmm = D.MixtureSameFamily(mix, comp)\n",
    "\n",
    "    fitted_samples = gmm.sample((5000,))\n",
    "\n",
    "plt.hist(fitted_samples.numpy(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e0b1b762-a68b-41eb-94d5-c2c614a24f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the sampling approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "61a9a590-fd2d-4ef4-8561-f160d0a5d508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  75.6145, Valid: 602.0123\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter logits (Tensor of shape (10,)) of distribution Categorical(logits: torch.Size([10])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [206]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 33\u001b[0m     mix \u001b[38;5;241m=\u001b[39m \u001b[43mD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     comp \u001b[38;5;241m=\u001b[39m D\u001b[38;5;241m.\u001b[39mNormal(component_mu, th\u001b[38;5;241m.\u001b[39mexp(component_log_std))\n\u001b[1;32m     35\u001b[0m     gmm \u001b[38;5;241m=\u001b[39m D\u001b[38;5;241m.\u001b[39mMixtureSameFamily(mix, comp)\n",
      "File \u001b[0;32m~/torchenv/lib/python3.8/site-packages/torch/distributions/categorical.py:64\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     63\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCategorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/torchenv/lib/python3.8/site-packages/torch/distributions/distribution.py:55\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     53\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m---> 55\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28msuper\u001b[39m(Distribution, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter logits (Tensor of shape (10,)) of distribution Categorical(logits: torch.Size([10])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
     ]
    }
   ],
   "source": [
    "n_components = 10\n",
    "\n",
    "weight_logits = th.nn.Parameter(th.randn(n_components,))\n",
    "component_mu = th.nn.Parameter(th.randn(n_components,))\n",
    "component_log_std = th.nn.Parameter(th.randn(n_components,))\n",
    "\n",
    "params = [weight_logits, component_mu, component_log_std]\n",
    "opt = th.optim.Adam(params, lr = 0.01)\n",
    "\n",
    "best_valid_loss = th.inf \n",
    "patience = 500\n",
    "wait_counter = 0\n",
    "\n",
    "best_params = []\n",
    "\n",
    "train_y = y[:80,:]\n",
    "valid_y = repy[80:,:]\n",
    "\n",
    "for e in range(10000):\n",
    "    \n",
    "    sampled_alpha = sample_mixture_gaussians(weight_logits, component_mu, th.exp(component_log_std), train_y.shape[0], hard=True)\n",
    "    sampled_alpha = th.tile(sampled_alpha[:,None], (1,n_trials))\n",
    "\n",
    "    prob_one = th.sigmoid(sampled_alpha)\n",
    "    loglik = ((train_y * th.log(prob_one) + (1-train_y) * th.log(1-prob_one))).sum(1)\n",
    "    loss = -loglik.mean()\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    with th.no_grad():\n",
    "        mix = D.Categorical(logits=weight_logits)\n",
    "        comp = D.Normal(component_mu, th.exp(component_log_std))\n",
    "        gmm = D.MixtureSameFamily(mix, comp)\n",
    "\n",
    "        \n",
    "        alpha = th.tile(abilities_grid, (valid_y.shape[0], valid_y.shape[1],1))\n",
    "        prob_one = th.sigmoid(alpha)\n",
    "        logprior = gmm.log_prob(alpha)\n",
    "        loglik = ((valid_y * th.log(prob_one) + (1-valid_y) * th.log(1-prob_one))).sum(1)\n",
    "        valid_loss = -th.logsumexp(loglik + logprior[:,0,:], dim=1).sum()\n",
    "\n",
    "\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_params = copy.deepcopy(params)\n",
    "            wait_counter = 0\n",
    "        else:\n",
    "            wait_counter += 1\n",
    "        \n",
    "        if wait_counter >= patience:\n",
    "            break\n",
    "        \n",
    "    if e % 100 == 0:\n",
    "        print(\"Train: %8.4f, Valid: %8.4f\" % (loss.item(), valid_loss.item()))\n",
    "    \n",
    "    \n",
    "with th.no_grad():\n",
    "    weight_logits, component_mu, component_log_std = best_params\n",
    "    mix = D.Categorical(logits=weight_logits)\n",
    "    comp = D.Normal(component_mu, th.exp(component_log_std))\n",
    "    gmm = D.MixtureSameFamily(mix, comp)\n",
    "\n",
    "    fitted_samples = gmm.sample((5000,))\n",
    "\n",
    "plt.hist(fitted_samples.numpy(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b41069d5-e0a0-4ade-b518-1abfde6117a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 124.6394, Valid: 589.1577\n",
      "Train: 138.3219, Valid: 589.0307\n",
      "Train: 136.7190, Valid: 588.9079\n",
      "Train: 132.4312, Valid: 588.7846\n",
      "Train: 129.0193, Valid: 588.6708\n",
      "Train: 144.6058, Valid: 588.5452\n",
      "Train: 136.0887, Valid: 588.4255\n",
      "Train: 144.6889, Valid: 588.3069\n",
      "Train: 124.0164, Valid: 588.1868\n",
      "Train: 163.3638, Valid: 588.0729\n",
      "Train: 124.8057, Valid: 587.9496\n",
      "Train: 132.7272, Valid: 587.8386\n",
      "Train: 128.2538, Valid: 587.7273\n",
      "Train: 136.1353, Valid: 587.6137\n",
      "Train: 135.6065, Valid: 587.4987\n",
      "Train: 142.0761, Valid: 587.3851\n",
      "Train: 155.0099, Valid: 587.2712\n",
      "Train: 151.5360, Valid: 587.1552\n",
      "Train: 126.2902, Valid: 587.0523\n",
      "Train: 149.2300, Valid: 586.9416\n",
      "Train: 137.6225, Valid: 586.8326\n",
      "Train: 149.6550, Valid: 586.7274\n",
      "Train: 127.2142, Valid: 586.6213\n",
      "Train: 144.9830, Valid: 586.5084\n",
      "Train: 122.2919, Valid: 586.4008\n",
      "Train: 147.0993, Valid: 586.2943\n",
      "Train: 133.3487, Valid: 586.1911\n",
      "Train: 124.1325, Valid: 586.0867\n",
      "Train: 121.1937, Valid: 585.9851\n",
      "Train: 120.2776, Valid: 585.8817\n",
      "Train: 130.9004, Valid: 585.7820\n",
      "Train: 122.1432, Valid: 585.6910\n",
      "Train: 124.2506, Valid: 585.5914\n",
      "Train: 133.9695, Valid: 585.4955\n",
      "Train: 124.4185, Valid: 585.4041\n",
      "Train: 127.7494, Valid: 585.3086\n",
      "Train: 143.2813, Valid: 585.2106\n",
      "Train: 136.3306, Valid: 585.1094\n",
      "Train: 138.7023, Valid: 585.0127\n",
      "Train: 137.4220, Valid: 584.9187\n",
      "Train: 124.2423, Valid: 584.8246\n",
      "Train: 131.2978, Valid: 584.7334\n",
      "Train: 119.3270, Valid: 584.6437\n",
      "Train: 128.9881, Valid: 584.5566\n",
      "Train: 126.8421, Valid: 584.4783\n",
      "Train: 124.2383, Valid: 584.3942\n",
      "Train: 140.2675, Valid: 584.3066\n",
      "Train: 126.6760, Valid: 584.2227\n",
      "Train: 135.7885, Valid: 584.1393\n",
      "Train: 121.1010, Valid: 584.0479\n",
      "Train: 156.1925, Valid: 583.9656\n",
      "Train: 128.0714, Valid: 583.8791\n",
      "Train: 132.9394, Valid: 583.7893\n",
      "Train: 131.7966, Valid: 583.7039\n",
      "Train: 125.3986, Valid: 583.6177\n",
      "Train: 128.7253, Valid: 583.5402\n",
      "Train: 127.3583, Valid: 583.4662\n",
      "Train: 124.7864, Valid: 583.3836\n",
      "Train: 123.3613, Valid: 583.3044\n",
      "Train: 115.7833, Valid: 583.2285\n",
      "Train: 112.0617, Valid: 583.1514\n",
      "Train: 111.7709, Valid: 583.0738\n",
      "Train: 123.5319, Valid: 582.9962\n",
      "Train: 112.5420, Valid: 582.9181\n",
      "Train: 129.3568, Valid: 582.8423\n",
      "Train: 127.0823, Valid: 582.7637\n",
      "Train: 115.5189, Valid: 582.6875\n",
      "Train: 114.0542, Valid: 582.6121\n",
      "Train: 139.2721, Valid: 582.5408\n",
      "Train: 128.3641, Valid: 582.4631\n",
      "Train: 114.6061, Valid: 582.3848\n",
      "Train: 116.8711, Valid: 582.3113\n",
      "Train: 119.4111, Valid: 582.2372\n",
      "Train: 122.8686, Valid: 582.1666\n",
      "Train: 111.0537, Valid: 582.0973\n",
      "Train: 106.2628, Valid: 582.0279\n",
      "Train: 120.3041, Valid: 581.9655\n",
      "Train: 111.0764, Valid: 581.9030\n",
      "Train: 122.3211, Valid: 581.8353\n",
      "Train: 120.6674, Valid: 581.7691\n",
      "Train: 119.9243, Valid: 581.7000\n",
      "Train: 123.0867, Valid: 581.6351\n",
      "Train: 129.7282, Valid: 581.5702\n",
      "Train: 114.7048, Valid: 581.5063\n",
      "Train: 141.3399, Valid: 581.4399\n",
      "Train: 104.8315, Valid: 581.3782\n",
      "Train: 125.9605, Valid: 581.3148\n",
      "Train:  96.7737, Valid: 581.2479\n",
      "Train: 113.2108, Valid: 581.1844\n",
      "Train: 117.0640, Valid: 581.1202\n",
      "Train: 111.0943, Valid: 581.0557\n",
      "Train: 106.7014, Valid: 580.9957\n",
      "Train: 112.9768, Valid: 580.9362\n",
      "Train: 116.4058, Valid: 580.8757\n",
      "Train: 108.9331, Valid: 580.8108\n",
      "Train: 123.2475, Valid: 580.7527\n",
      "Train: 111.7885, Valid: 580.7020\n",
      "Train: 102.2417, Valid: 580.6393\n",
      "Train: 126.6326, Valid: 580.5797\n",
      "Train: 105.3917, Valid: 580.5219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  2.,   1.,   1.,   3.,   9.,  20.,  28.,  36.,  49.,  59.,  73.,\n",
       "         74., 102., 120., 136., 154., 141., 179., 216., 287., 280., 341.,\n",
       "        328., 319., 335., 289., 229., 190., 172., 133.,  97.,  71.,  54.,\n",
       "         45.,  31.,  33.,  44.,  45.,  34.,  40.,  34.,  40.,  26.,  22.,\n",
       "         30.,   9.,  18.,   9.,   7.,   5.]),\n",
       " array([-7.515113  , -7.2225432 , -6.929974  , -6.6374044 , -6.3448353 ,\n",
       "        -6.0522656 , -5.7596965 , -5.467127  , -5.1745577 , -4.881988  ,\n",
       "        -4.589419  , -4.2968493 , -4.00428   , -3.7117105 , -3.419141  ,\n",
       "        -3.1265717 , -2.8340023 , -2.5414329 , -2.2488635 , -1.9562941 ,\n",
       "        -1.6637247 , -1.3711553 , -1.0785859 , -0.78601646, -0.49344707,\n",
       "        -0.20087767,  0.09169174,  0.38426116,  0.67683053,  0.9694    ,\n",
       "         1.2619693 ,  1.5545387 ,  1.8471082 ,  2.1396775 ,  2.432247  ,\n",
       "         2.7248163 ,  3.0173857 ,  3.3099551 ,  3.6025248 ,  3.8950942 ,\n",
       "         4.1876636 ,  4.4802327 ,  4.7728024 ,  5.0653715 ,  5.357941  ,\n",
       "         5.6505103 ,  5.94308   ,  6.235649  ,  6.5282187 ,  6.820788  ,\n",
       "         7.1133575 ], dtype=float32),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_components = 10\n",
    "min_val = -5\n",
    "max_val = 5\n",
    "\n",
    "weight_logits = th.nn.Parameter(th.randn(n_components,))\n",
    "component_mu = th.linspace(min_val, max_val, n_components)\n",
    "component_log_std = th.zeros_like(component_mu)\n",
    "\n",
    "params = [weight_logits]\n",
    "opt = th.optim.Adam(params, lr = 0.0001)\n",
    "\n",
    "best_valid_loss = th.inf \n",
    "patience = 100\n",
    "wait_counter = 0\n",
    "\n",
    "best_params = []\n",
    "\n",
    "train_y = y[:80,:]\n",
    "valid_y = repy[80:,:]\n",
    "\n",
    "for e in range(10000):\n",
    "    \n",
    "    sampled_alpha = sample_mixture_gaussians(weight_logits, component_mu, th.exp(component_log_std), train_y.shape[0], hard=True)\n",
    "    sampled_alpha = th.tile(sampled_alpha[:,None], (1,n_trials))\n",
    "\n",
    "    prob_one = th.sigmoid(sampled_alpha)\n",
    "    loglik = ((train_y * th.log(prob_one) + (1-train_y) * th.log(1-prob_one))).sum(1)\n",
    "    loss = -loglik.mean()\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    with th.no_grad():\n",
    "        mix = D.Categorical(logits=weight_logits)\n",
    "        comp = D.Normal(component_mu, th.exp(component_log_std))\n",
    "        gmm = D.MixtureSameFamily(mix, comp)\n",
    "\n",
    "        \n",
    "        alpha = th.tile(abilities_grid, (valid_y.shape[0], valid_y.shape[1],1))\n",
    "        prob_one = th.sigmoid(alpha)\n",
    "        logprior = gmm.log_prob(alpha)\n",
    "        loglik = ((valid_y * th.log(prob_one) + (1-valid_y) * th.log(1-prob_one))).sum(1)\n",
    "        valid_loss = -th.logsumexp(loglik + logprior[:,0,:], dim=1).sum()\n",
    "\n",
    "\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_params = copy.deepcopy(params)\n",
    "            wait_counter = 0\n",
    "        else:\n",
    "            wait_counter += 1\n",
    "        \n",
    "        if wait_counter >= patience:\n",
    "            break\n",
    "        \n",
    "    if e % 100 == 0:\n",
    "        print(\"Train: %8.4f, Valid: %8.4f\" % (loss.item(), valid_loss.item()))\n",
    "    \n",
    "    \n",
    "with th.no_grad():\n",
    "    weight_logits = best_params[0]\n",
    "    mix = D.Categorical(logits=weight_logits)\n",
    "    comp = D.Normal(component_mu, th.exp(component_log_std))\n",
    "    gmm = D.MixtureSameFamily(mix, comp)\n",
    "\n",
    "    fitted_samples = gmm.sample((5000,))\n",
    "\n",
    "plt.hist(fitted_samples.numpy(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125085a3-4c4c-4bf4-832a-978434eaae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit alphas using uniform prior then sample from that distribution, with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2282afec-a69a-4ec6-ae95-4fbaa9f91c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_alpha = th.nn.Parameter(\n",
    "params = [weight_logits, component_mu, component_log_std]\n",
    "opt = th.optim.Adam(params, lr = 0.01)\n",
    "\n",
    "best_valid_loss = th.inf \n",
    "patience = 500\n",
    "wait_counter = 0\n",
    "\n",
    "best_params = []\n",
    "\n",
    "train_y = y[:80,:]\n",
    "valid_y = repy[80:,:]\n",
    "\n",
    "for e in range(10000):\n",
    "    \n",
    "    sampled_alpha = sample_mixture_gaussians(weight_logits, component_mu, th.exp(component_log_std), train_y.shape[0], hard=True)\n",
    "    sampled_alpha = th.tile(sampled_alpha[:,None], (1,n_trials))\n",
    "\n",
    "    prob_one = th.sigmoid(sampled_alpha)\n",
    "    loglik = ((train_y * th.log(prob_one) + (1-train_y) * th.log(1-prob_one))).sum(1)\n",
    "    loss = -loglik.mean()\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    with th.no_grad():\n",
    "        mix = D.Categorical(logits=weight_logits)\n",
    "        comp = D.Normal(component_mu, th.exp(component_log_std))\n",
    "        gmm = D.MixtureSameFamily(mix, comp)\n",
    "\n",
    "        \n",
    "        alpha = th.tile(abilities_grid, (valid_y.shape[0], valid_y.shape[1],1))\n",
    "        prob_one = th.sigmoid(alpha)\n",
    "        logprior = gmm.log_prob(alpha)\n",
    "        loglik = ((valid_y * th.log(prob_one) + (1-valid_y) * th.log(1-prob_one))).sum(1)\n",
    "        valid_loss = -th.logsumexp(loglik + logprior[:,0,:], dim=1).sum()\n",
    "\n",
    "\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_params = copy.deepcopy(params)\n",
    "            wait_counter = 0\n",
    "        else:\n",
    "            wait_counter += 1\n",
    "        \n",
    "        if wait_counter >= patience:\n",
    "            break\n",
    "        \n",
    "    if e % 100 == 0:\n",
    "        print(\"Train: %8.4f, Valid: %8.4f\" % (loss.item(), valid_loss.item()))\n",
    "    \n",
    "    \n",
    "with th.no_grad():\n",
    "    weight_logits, component_mu, component_log_std = best_params\n",
    "    mix = D.Categorical(logits=weight_logits)\n",
    "    comp = D.Normal(component_mu, th.exp(component_log_std))\n",
    "    gmm = D.MixtureSameFamily(mix, comp)\n",
    "\n",
    "    fitted_samples = gmm.sample((5000,))\n",
    "\n",
    "plt.hist(fitted_samples.numpy(), bins=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
